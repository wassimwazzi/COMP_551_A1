{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d2f6160",
   "metadata": {},
   "source": [
    "# Applied Machine Learning: Mini Project 1 - Group 46"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf327d5",
   "metadata": {},
   "source": [
    "## Dataset 1: Adult Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92865918",
   "metadata": {},
   "source": [
    "For the first part of the project, we begin our analysis on the provided Adult dataset. \n",
    "<br>Most of our helper functions can be found in the ***tools.py*** file.\n",
    "<br>We start by importing the dataset and storing the equivalent data in Pandas Dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f085c81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>284582</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32555</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32560 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  fnlwgt    education  education-num  \\\n",
       "0       50   Self-emp-not-inc   83311    Bachelors             13   \n",
       "1       38            Private  215646      HS-grad              9   \n",
       "2       53            Private  234721         11th              7   \n",
       "3       28            Private  338409    Bachelors             13   \n",
       "4       37            Private  284582      Masters             14   \n",
       "...    ...                ...     ...          ...            ...   \n",
       "32555   27            Private  257302   Assoc-acdm             12   \n",
       "32556   40            Private  154374      HS-grad              9   \n",
       "32557   58            Private  151910      HS-grad              9   \n",
       "32558   22            Private  201490      HS-grad              9   \n",
       "32559   52       Self-emp-inc  287927      HS-grad              9   \n",
       "\n",
       "            marital-status          occupation    relationship    race  \\\n",
       "0       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "1                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "2       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "3       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "4       Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32555   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32556   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32557              Widowed        Adm-clerical       Unmarried   White   \n",
       "32558        Never-married        Adm-clerical       Own-child   White   \n",
       "32559   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           sex  capital-gain  capital-loss  hours-per-week  native-country  \\\n",
       "0         Male             0             0              13   United-States   \n",
       "1         Male             0             0              40   United-States   \n",
       "2         Male             0             0              40   United-States   \n",
       "3       Female             0             0              40            Cuba   \n",
       "4       Female             0             0              40   United-States   \n",
       "...        ...           ...           ...             ...             ...   \n",
       "32555   Female             0             0              38   United-States   \n",
       "32556     Male             0             0              40   United-States   \n",
       "32557   Female             0             0              40   United-States   \n",
       "32558     Male             0             0              20   United-States   \n",
       "32559   Female         15024             0              40   United-States   \n",
       "\n",
       "        label  \n",
       "0       <=50K  \n",
       "1       <=50K  \n",
       "2       <=50K  \n",
       "3       <=50K  \n",
       "4       <=50K  \n",
       "...       ...  \n",
       "32555   <=50K  \n",
       "32556    >50K  \n",
       "32557   <=50K  \n",
       "32558   <=50K  \n",
       "32559    >50K  \n",
       "\n",
       "[32560 rows x 15 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tools\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "import warnings\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "import sklearn\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", sep=\",\")\n",
    "df.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation',\n",
    "              'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', \n",
    "              'label']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383dd0b2",
   "metadata": {},
   "source": [
    "Now, we try cleaning our data by dropping irrelevant features that could obstruct the performance of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d32e38d7-5fe6-4234-a654-0d640598e26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32555</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32560 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  education-num       marital-status  \\\n",
       "0       50   Self-emp-not-inc             13   Married-civ-spouse   \n",
       "1       38            Private              9             Divorced   \n",
       "2       53            Private              7   Married-civ-spouse   \n",
       "3       28            Private             13   Married-civ-spouse   \n",
       "4       37            Private             14   Married-civ-spouse   \n",
       "...    ...                ...            ...                  ...   \n",
       "32555   27            Private             12   Married-civ-spouse   \n",
       "32556   40            Private              9   Married-civ-spouse   \n",
       "32557   58            Private              9              Widowed   \n",
       "32558   22            Private              9        Never-married   \n",
       "32559   52       Self-emp-inc              9   Married-civ-spouse   \n",
       "\n",
       "               occupation    relationship    race      sex  capital-gain  \\\n",
       "0         Exec-managerial         Husband   White     Male             0   \n",
       "1       Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "2       Handlers-cleaners         Husband   Black     Male             0   \n",
       "3          Prof-specialty            Wife   Black   Female             0   \n",
       "4         Exec-managerial            Wife   White   Female             0   \n",
       "...                   ...             ...     ...      ...           ...   \n",
       "32555        Tech-support            Wife   White   Female             0   \n",
       "32556   Machine-op-inspct         Husband   White     Male             0   \n",
       "32557        Adm-clerical       Unmarried   White   Female             0   \n",
       "32558        Adm-clerical       Own-child   White     Male             0   \n",
       "32559     Exec-managerial            Wife   White   Female         15024   \n",
       "\n",
       "       capital-loss  hours-per-week  native-country   label  \n",
       "0                 0              13   United-States   <=50K  \n",
       "1                 0              40   United-States   <=50K  \n",
       "2                 0              40   United-States   <=50K  \n",
       "3                 0              40            Cuba   <=50K  \n",
       "4                 0              40   United-States   <=50K  \n",
       "...             ...             ...             ...     ...  \n",
       "32555             0              38   United-States   <=50K  \n",
       "32556             0              40   United-States    >50K  \n",
       "32557             0              40   United-States   <=50K  \n",
       "32558             0              20   United-States   <=50K  \n",
       "32559             0              40   United-States    >50K  \n",
       "\n",
       "[32560 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping noising features\n",
    "df = df.drop(columns=['fnlwgt','education'])\n",
    "\n",
    "# replacing all invalid entries by NaN\n",
    "df = tools.clean_df(df)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26b759b-0af5-4295-a68d-5a768b474274",
   "metadata": {},
   "source": [
    "We dropped features that are irrelevant, and replaced any invalid entry by \"NaN\". Now we need to convert discrete variables into multiple variables by using one-hot encoding, provided by sklearn. We also need to replace all \"NaN\" entries by the mean of the column for continuous data, and by the mode of the column for discrete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfca56ac-91ae-4a2f-92df-d0c7e7948783",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape =  (32560, 88)\n"
     ]
    }
   ],
   "source": [
    "labels = df.loc[:, 'label'].to_numpy() # array to label string\n",
    "df = df.iloc[:, 0:-1] # drop label in dataframe\n",
    "# do label encoding on Y\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels)\n",
    "#print(\"classes = \", le.classes_)\n",
    "Y = le.transform(labels)\n",
    "\n",
    "\n",
    "# select the columns with discrete variables\n",
    "discrete_columns_selector = selector(dtype_include=object)\n",
    "discrete_columns = discrete_columns_selector(df)\n",
    "df_discrete = df[discrete_columns]\n",
    "\n",
    "\n",
    "# replacing nan values with mode of respective column\n",
    "for (column_name, column_data) in df_discrete.iteritems():\n",
    "    mode = df_discrete[column_name].mode(dropna=True)[0]\n",
    "    df_discrete[column_name] = df_discrete[column_name].fillna(mode)\n",
    "    \n",
    "    \n",
    "# select the columns with continuous variables\n",
    "continuous_columns_selector = selector(dtype_include = int)\n",
    "continuous_columns = continuous_columns_selector(df)\n",
    "df_continuous = df[continuous_columns]\n",
    "df_continuous.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# replacing nan values with mean of respective column\n",
    "for (column_name, column_data) in df_continuous.iteritems():\n",
    "    mean = df_continuous[column_name].mean(skipna = True)\n",
    "    df_continuous[column_name] = df_continuous[column_name].fillna(mean)\n",
    "    \n",
    "\n",
    "# do one hot encoding on dsicrete variables in dataframe\n",
    "discrete_encoded = tools.oneHotEncoding(df_discrete)\n",
    "discrete_encoded.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# merge the continuous and discrete and label features into one df\n",
    "df_encoded = pd.concat([df_continuous,discrete_encoded],  axis=1, join='inner')\n",
    "\n",
    "X = df_encoded.to_numpy()\n",
    "\n",
    "print(\"shape = \", df_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2644115-f23d-4b59-916c-986bfd6465dc",
   "metadata": {},
   "source": [
    "We have succesfully converted the discrete variables into multiple variables. We now have 88 features compared to the 13 we had at the start."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855c9d37",
   "metadata": {},
   "source": [
    "* ### 5-fold cross validation with the KNN algorithm:\n",
    "Now, we run the 5-fold cross validation on the encoded data frame with the KNN algorithm, with K ranging from 1 to 20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7f804b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k=1</th>\n",
       "      <th>k=2</th>\n",
       "      <th>k=3</th>\n",
       "      <th>k=4</th>\n",
       "      <th>k=5</th>\n",
       "      <th>k=6</th>\n",
       "      <th>k=7</th>\n",
       "      <th>k=8</th>\n",
       "      <th>k=9</th>\n",
       "      <th>k=10</th>\n",
       "      <th>k=11</th>\n",
       "      <th>k=12</th>\n",
       "      <th>k=13</th>\n",
       "      <th>k=14</th>\n",
       "      <th>k=15</th>\n",
       "      <th>k=16</th>\n",
       "      <th>k=17</th>\n",
       "      <th>k=18</th>\n",
       "      <th>k=19</th>\n",
       "      <th>k=20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.817875</td>\n",
       "      <td>0.842291</td>\n",
       "      <td>0.840295</td>\n",
       "      <td>0.848403</td>\n",
       "      <td>0.847789</td>\n",
       "      <td>0.852518</td>\n",
       "      <td>0.850215</td>\n",
       "      <td>0.852303</td>\n",
       "      <td>0.850584</td>\n",
       "      <td>0.852396</td>\n",
       "      <td>0.850522</td>\n",
       "      <td>0.853624</td>\n",
       "      <td>0.852365</td>\n",
       "      <td>0.853931</td>\n",
       "      <td>0.853317</td>\n",
       "      <td>0.853532</td>\n",
       "      <td>0.851505</td>\n",
       "      <td>0.852795</td>\n",
       "      <td>0.852027</td>\n",
       "      <td>0.85344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        k=1       k=2       k=3       k=4       k=5       k=6       k=7  \\\n",
       "0  0.817875  0.842291  0.840295  0.848403  0.847789  0.852518  0.850215   \n",
       "\n",
       "        k=8       k=9      k=10      k=11      k=12      k=13      k=14  \\\n",
       "0  0.852303  0.850584  0.852396  0.850522  0.853624  0.852365  0.853931   \n",
       "\n",
       "       k=15      k=16      k=17      k=18      k=19     k=20  \n",
       "0  0.853317  0.853532  0.851505  0.852795  0.852027  0.85344  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_cross_val = tools.l_fold_cross_validation_KNN(L=5, X=X, Y=Y, K=[k for k in range(1,21)])\n",
    "columns = [\"k=\" + str(i) for i in range(1,21)]\n",
    "KNN_cross_val_results = pd.DataFrame(columns=columns)\n",
    "KNN_cross_val_results.loc[0]=KNN_cross_val\n",
    "KNN_cross_val_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd2949d",
   "metadata": {},
   "source": [
    "We now analyze our results for different values of K:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3b5eab2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy =  0.8539312039312039 , achieved for K =  14\n"
     ]
    }
   ],
   "source": [
    "argmax = KNN_cross_val.argmax()\n",
    "print(\"best accuracy = \", KNN_cross_val.max(), \", achieved for K = \", argmax+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf4744f",
   "metadata": {},
   "source": [
    "Given the previous results, we can deduct that before scaling, the best performing KNN model was the one where K is 14."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1ab8c4",
   "metadata": {},
   "source": [
    "\n",
    "Due to computational complexity, we will assume that our model performs performs best when K=14 even when we add feature scaling to it (instead of testing out all combinations of feature scaling for all possible K values). We have decided to alter our model by scaling the following features: age (for obvious reasons), education-num (which lists the level of education of an individual), hours-per-week, capital-gain, and capital-loss. We believed those to be the most relevant features in our model. In order to determine when our model performs best, we wrote a function that tests it out for different scales for each relevant feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f4b53b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now scaling age by 10\n",
      "Now scaling age by 25\n",
      "Now scaling age by 50\n",
      "Now scaling age by 100\n",
      "Now scaling age by 150\n",
      "Now scaling age by 200\n",
      "Now scaling education-num by 10\n",
      "Now scaling education-num by 25\n",
      "Now scaling education-num by 50\n",
      "Now scaling education-num by 100\n",
      "Now scaling education-num by 150\n",
      "Now scaling education-num by 200\n",
      "Now scaling hours-per-week by 10\n",
      "Now scaling hours-per-week by 25\n",
      "Now scaling hours-per-week by 50\n",
      "Now scaling hours-per-week by 100\n",
      "Now scaling hours-per-week by 150\n",
      "Now scaling hours-per-week by 200\n",
      "Now scaling capital-gain by 10\n",
      "Now scaling capital-gain by 25\n",
      "Now scaling capital-gain by 50\n",
      "Now scaling capital-gain by 100\n",
      "Now scaling capital-gain by 150\n",
      "Now scaling capital-gain by 200\n",
      "Now scaling capital-loss by 10\n",
      "Now scaling capital-loss by 25\n",
      "Now scaling capital-loss by 50\n",
      "Now scaling capital-loss by 100\n",
      "Now scaling capital-loss by 150\n",
      "Now scaling capital-loss by 200\n"
     ]
    }
   ],
   "source": [
    "X_scaling = df_encoded\n",
    "scalable_features = ('age', 'education-num', 'hours-per-week', 'capital-gain', 'capital-loss')\n",
    "KNN_cross_val_scaled = tools.l_fold_cross_validation_KNN_scaling_test(L=5, X=X_scaling, Y=Y, K=14, scalable_features=scalable_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ee782",
   "metadata": {},
   "source": [
    "Let's visualize the results of our test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d65de4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tools.plot_scaling_results(KNN_cross_val_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa41f8a",
   "metadata": {},
   "source": [
    "We can deduct from this that scaling has not brought any relevant value to our model's performance. Thus, we have decided not to apply any scaling to our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f45bf42",
   "metadata": {},
   "source": [
    "* ### 5-fold cross validation on that same data with the Decision Tree algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75eb01f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "Done\n",
      "Performing 5-fold-cross-validation on  720  permutations of hyperparameters took  340.2424571  seconds\n"
     ]
    }
   ],
   "source": [
    "DT_cross_val = tools.l_fold_cross_validation_DT(L=5, X=X, Y=Y, criterion=[\"gini\", \"entropy\"],splitter=[\"best\",\"random\"],max_depth=[10,20,30,40,50],min_impurity_decrease=[0.2,0.1,0.05,0.025,0.01,0],min_samples_leaf=[1,5,10,15,20,25])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaddd02",
   "metadata": {},
   "source": [
    "We will now try to find the best hyperparameters for our Decision Tree algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19237fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyperparmater values are: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>splitter</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_impurity_decrease</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time_req</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.858876</td>\n",
       "      <td>1.063344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    criterion splitter max_depth  min_impurity_decrease min_samples_leaf  \\\n",
       "538   entropy     best        50                    0.0               20   \n",
       "\n",
       "     accuracy  time_req  \n",
       "538  0.858876  1.063344  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hp = DT_cross_val[DT_cross_val.accuracy == DT_cross_val.accuracy.max()]\n",
    "# if we have a tie of best hyperparameters, choose the one with the fastest time\n",
    "if best_hp.shape[0]>1:\n",
    "    best_hp = best_hp[best_hp.time_req == best_hp.time_req.min()]\n",
    "print(\"best hyperparmater values are: \")\n",
    "best_hp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee9955e",
   "metadata": {},
   "source": [
    "Looking at the above table, we can easily see which are the best parameters for our Decision Tree algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b4f86d",
   "metadata": {},
   "source": [
    "* ### L-fold cross validation with KNN algorithm on that same data with L > 5:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb8eb47",
   "metadata": {},
   "source": [
    "Now we want to run the same experiment but with larger subsets of the training validation data. Since this will be very time-consuming, we will run the cross_validation with a smaller range of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d8b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in [10,15,20,25]:\n",
    "    print(\"L = \", l)\n",
    "    KNN_cross_val = tools.l_fold_cross_validation_KNN(L=l, X=X, Y=Y, K=[5,10,14,15])\n",
    "    argmax = KNN_cross_val.argmax()\n",
    "    print(\"the best accuracy = \", KNN_cross_val.max(), \", achieved for K = \", argmax+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896df246",
   "metadata": {},
   "source": [
    "We want to understand how the size of a dataset impacts both the training and validation error.\n",
    "<br>We can see that as L increases, or more specifically when L > 5, setting K = 2 instead of 14 results in a better performance for our model. As for the accuracy, it has increased by 0.1%, which is not enough to deduct anything (this variation can be due to the finite size of the dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94e3c16",
   "metadata": {},
   "source": [
    "* ### L-fold cross validation with the Decision Tree algorithm on that same data with L > 5:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fda381",
   "metadata": {},
   "source": [
    "As for the KNN algorithm, we will run the cross_validation with a smaller range of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf78d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in [10,15,20,25]:\n",
    "    print(\"L = \", l)\n",
    "    print('Loading... This might take a while')\n",
    "    DT_cross_val = tools.l_fold_cross_validation_DT(L=l, X=X, Y=Y,criterion=[\"gini\", \"entropy\"],splitter=[\"best\",\"random\"],max_depth=[10,15],min_impurity_decrease=[0.1,0.025,0],min_samples_leaf=[1,5,10,15,20,25])\n",
    "    best_hp = DT_cross_val[DT_cross_val.accuracy == DT_cross_val.accuracy.max()]\n",
    "    # if we have a tie of best hyperparameters, choose the one with the fastest time\n",
    "    if best_hp.shape[0]>1:\n",
    "        best_hp = best_hp[best_hp.time_req == best_hp.time_req.min()]\n",
    "    print(\"The best hyperparmater values are:\")\n",
    "    display(best_hp)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faf0791",
   "metadata": {},
   "source": [
    "We want to understand how the size of a dataset impacts both the training and validation error\n",
    "<br>Looking at the above tables, we notice that as L increases, most hyperparameters that lead to optimal results are different than when L = 5 (Gini has been the better criterion over Entropy - maximum depth has decreased significantly ...), although the accuracy remains relatively unchanged. This means that we can manage to achieve the same accuracy as L increases by tweaking our hyperparameters as was seen in the tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7db3831",
   "metadata": {},
   "source": [
    "### Applying our model on unseen data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf4372f",
   "metadata": {},
   "source": [
    "Now, let's check our performance on the test data. \n",
    "First, we have to load the test data, and perform the same cleaning as we did on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "228c57e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16280, 87)\n"
     ]
    }
   ],
   "source": [
    "# load and clean test data\n",
    "\n",
    "df_test = pd.read_csv(\"C:/Users/admin/Desktop/COMP 551/Assignments/COMP551_A1/adult.test\", sep=\",\")\n",
    "df_test.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation',\n",
    "              'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', \n",
    "              'label']\n",
    "df_test = df_test.drop(columns=['fnlwgt','education'])\n",
    "\n",
    "# replacing all invalid entries by NaN\n",
    "df_test = tools.clean_df(df_test)\n",
    "labels = df_test.loc[:, 'label'].to_numpy() # array ot label string\n",
    "df_test = df_test.iloc[:, 0:-1] # drop label in dataframe\n",
    "# do label encoding on Y\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels)\n",
    "#print(\"classes = \", le.classes_)\n",
    "Y_test = le.transform(labels)\n",
    "\n",
    "\n",
    "# select the columns with discrete variables\n",
    "discrete_columns_selector = selector(dtype_include=object)\n",
    "discrete_columns = discrete_columns_selector(df_test)\n",
    "df_discrete = df_test[discrete_columns]\n",
    "\n",
    "\n",
    "# replacing nan values with mode of respective column\n",
    "for (column_name, column_data) in df_discrete.iteritems():\n",
    "    mode = df_discrete[column_name].mode(dropna=True)[0]\n",
    "    df_discrete[column_name] = df_discrete[column_name].fillna(mode)\n",
    "    \n",
    "    \n",
    "# select the columns with continuous variables\n",
    "continuous_columns_selector = selector(dtype_include = int)\n",
    "continuous_columns = continuous_columns_selector(df_test)\n",
    "df_continuous = df_test[continuous_columns]\n",
    "df_continuous.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# replacing nan values with mean of respective column\n",
    "for (column_name, column_data) in df_continuous.iteritems():\n",
    "    mean = df_continuous[column_name].mean(skipna = True)\n",
    "    df_continuous[column_name] = df_continuous[column_name].fillna(mean)\n",
    "    \n",
    "\n",
    "# do one hot encoding on dsicrete variables in dataframe\n",
    "discrete_encoded = tools.oneHotEncoding(df_discrete)\n",
    "discrete_encoded.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# merge the continuous and discrete and label features into one df\n",
    "df_encoded_test = pd.concat([df_continuous,discrete_encoded],  axis=1, join='inner')\n",
    "\n",
    "print(df_encoded_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f781ae04",
   "metadata": {},
   "source": [
    "We notice the test data has less columns than the training data, so we need to fill the missing columns with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8421ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add missing column to training set\n",
    "for i in range(len(df_encoded.columns)):\n",
    "    if df_encoded.columns[i] != df_encoded_test.columns[i]:\n",
    "        df_encoded_test.insert(loc=i, column=df_encoded.columns[i], value=[0]*df_encoded_test.shape[0])\n",
    "\n",
    "X_test = df_encoded_test.to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8caba41",
   "metadata": {},
   "source": [
    "* ### KNN on unseen data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1ee1d8",
   "metadata": {},
   "source": [
    "We now run our KNN model on unseen data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efbfb958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k =  2 the accuracy on the test data is:  0.8445945945945946\n",
      "for k =  14 the accuracy on the test data is:  0.8582923832923833\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "for k in [2,14]:\n",
    "    # see training data results on KNN using K=k\n",
    "    KNN_classifier = KNN(n_neighbors=k)\n",
    "    KNN_classifier.fit(X, Y) # fit the model using training data\n",
    "    Y_prediction = KNN_classifier.predict(X_test) # predict test data\n",
    "    accuracy = Y_prediction == Y_test\n",
    "    accuracy = np.sum(accuracy)  # number of correct predictions\n",
    "    score = accuracy / X_test.shape[0]  # ratio of correct prediction\n",
    "    print(\"for k = \", k, \"the accuracy on the test data is: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37def6f7",
   "metadata": {},
   "source": [
    "Just out of curiousity, we have also tested our model for K = 2 (which was the best performing value for when L > 5). \n",
    "<br>Otherwise, assuming our model performs best when K = 14, we can estimate an accuracy of 85.83% on unseen data with our KNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f713744",
   "metadata": {},
   "source": [
    "* ### Decision Tree algorithm on unseen data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33869199",
   "metadata": {},
   "source": [
    "Using the best hyperparameters for our model when L = 5, we run our Decision Tree algorithm on unseen data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e953c64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the best hyperparameters, the accuracy is:  0.8636363636363636\n"
     ]
    }
   ],
   "source": [
    "# DT\n",
    "# predict on test data using best hyperparameters\n",
    "DT_classifier = DT(criterion=\"entropy\", splitter=\"best\", max_depth=50,\n",
    "                min_impurity_decrease=0, min_samples_leaf=20)\n",
    "DT_classifier.fit(X, Y)\n",
    "Y_prediction = DT_classifier.predict(X_test)\n",
    "accuracy = Y_prediction == Y_test\n",
    "accuracy = np.sum(accuracy)  # number of correct predictions\n",
    "score = accuracy/X_test.shape[0]\n",
    "print(\"For the best hyperparameters, the accuracy is: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bdf403",
   "metadata": {},
   "source": [
    "<br>Assuming our model performs best under these parameters, we can estimate an accuracy of 86.36% on unseen data with our Decision Tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4739c1c",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1446edd3",
   "metadata": {},
   "source": [
    "## Dataset 2 : balance-scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454bb47f",
   "metadata": {},
   "source": [
    "For the second part of the project, we begin our analysis on the data set we have chosen: balance-scale. \n",
    "<br>Most of our helper functions can be found in the ***tools.py*** file.\n",
    "<br>We start by importing the dataset and storing the equivalent data in Pandas Dataframes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43589cfd",
   "metadata": {},
   "source": [
    "Now, we try cleaning our data by dropping irrelevant features that could obstruct the performance of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a93b630d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Left-Weight</th>\n",
       "      <th>Left-Distance</th>\n",
       "      <th>Right-Weight</th>\n",
       "      <th>Right-Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>L</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>L</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>L</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>L</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>B</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class  Left-Weight  Left-Distance  Right-Weight  Right-Distance\n",
       "0       R            1              1             1               2\n",
       "1       R            1              1             1               3\n",
       "2       R            1              1             1               4\n",
       "3       R            1              1             1               5\n",
       "4       R            1              1             2               1\n",
       "..    ...          ...            ...           ...             ...\n",
       "619     L            5              5             5               1\n",
       "620     L            5              5             5               2\n",
       "621     L            5              5             5               3\n",
       "622     L            5              5             5               4\n",
       "623     B            5              5             5               5\n",
       "\n",
       "[624 rows x 5 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tools\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "import warnings\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "import sklearn\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "df2 = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/balance-scale/balance-scale.data\", sep=\",\")\n",
    "df2.columns = ['Class', 'Left-Weight', 'Left-Distance', 'Right-Weight', 'Right-Distance']\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2701638f",
   "metadata": {},
   "source": [
    "The dataset we have chosen contains no missing values, hence we do not need to perform any data imputation. Also, all the features in the dataset are very relevant to our use-case which means we do not need to drop any potentially noisy feature.\n",
    "<br>Firstly, we will have to encode our 'Class' column by mapping each of the 3 possible values to an integer.\n",
    "<br>After that, we will need to seperate our dataset into a training set and a test set, and will do respectively using 2/3 and 1/3 as the proportions relative to the size of the set (the number of rows). These proportions are purely arbitrary, and were chosen as such because of popularity (another common ratio is 80:20 for the training-test sets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a31e15c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = round(df2.shape[0]*(2/3))\n",
    "df2_test = df2.iloc[split_index:, :]\n",
    "df2_train = df2.iloc[:split_index, :]\n",
    "\n",
    "labels2 = df2_train.loc[:, 'Class'].to_numpy() # array to label string\n",
    "labels2_test = df2_test.loc[:, 'Class'].to_numpy() # array to label string\n",
    "df2_train = df2_train.iloc[:, 1:] # drop label in dataframe\n",
    "df2_test = df2_test.iloc[:, 1:] # drop label in dataframe\n",
    "\n",
    "# do label encoding on Ys\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "le2.fit(labels2)\n",
    "\n",
    "Y2 = le2.transform(labels2)\n",
    "X2 = df2_train.to_numpy()\n",
    "\n",
    "Y2_test = le2.transform(labels2_test)\n",
    "X2_test = df2_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf39c24",
   "metadata": {},
   "source": [
    "* ### 5-fold cross validation with the KNN algorithm:\n",
    "Now, we run the 5-fold cross validation on the encoded data frame with the KNN algorithm, with K ranging from 1 to 20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ef160703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k=1</th>\n",
       "      <th>k=2</th>\n",
       "      <th>k=3</th>\n",
       "      <th>k=4</th>\n",
       "      <th>k=5</th>\n",
       "      <th>k=6</th>\n",
       "      <th>k=7</th>\n",
       "      <th>k=8</th>\n",
       "      <th>k=9</th>\n",
       "      <th>k=10</th>\n",
       "      <th>k=11</th>\n",
       "      <th>k=12</th>\n",
       "      <th>k=13</th>\n",
       "      <th>k=14</th>\n",
       "      <th>k=15</th>\n",
       "      <th>k=16</th>\n",
       "      <th>k=17</th>\n",
       "      <th>k=18</th>\n",
       "      <th>k=19</th>\n",
       "      <th>k=20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.761446</td>\n",
       "      <td>0.693976</td>\n",
       "      <td>0.780723</td>\n",
       "      <td>0.790361</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.814458</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.836145</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.840964</td>\n",
       "      <td>0.836145</td>\n",
       "      <td>0.840964</td>\n",
       "      <td>0.845783</td>\n",
       "      <td>0.838554</td>\n",
       "      <td>0.840964</td>\n",
       "      <td>0.838554</td>\n",
       "      <td>0.836145</td>\n",
       "      <td>0.840964</td>\n",
       "      <td>0.838554</td>\n",
       "      <td>0.828916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        k=1       k=2       k=3       k=4       k=5       k=6       k=7  \\\n",
       "0  0.761446  0.693976  0.780723  0.790361  0.819277  0.814458  0.831325   \n",
       "\n",
       "        k=8       k=9      k=10      k=11      k=12      k=13      k=14  \\\n",
       "0  0.836145  0.831325  0.840964  0.836145  0.840964  0.845783  0.838554   \n",
       "\n",
       "       k=15      k=16      k=17      k=18      k=19      k=20  \n",
       "0  0.840964  0.838554  0.836145  0.840964  0.838554  0.828916  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_cross_val = tools.l_fold_cross_validation_KNN(L=5, X=X2, Y=Y2, K=[k for k in range(1,21)])\n",
    "columns2 = [\"k=\" + str(i) for i in range(1,21)]\n",
    "KNN_cross_val_results = pd.DataFrame(columns=columns2)\n",
    "KNN_cross_val_results.loc[0]=KNN_cross_val\n",
    "KNN_cross_val_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308dc00a",
   "metadata": {},
   "source": [
    "We now analyze our results for different values of K:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "af764143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy =  0.8457831325301205 , achieved for K =  13\n"
     ]
    }
   ],
   "source": [
    "argmax = KNN_cross_val.argmax()\n",
    "print(\"best accuracy =\", KNN_cross_val.max(), \", achieved for K = \", argmax+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e533daec",
   "metadata": {},
   "source": [
    "Given the previous results, we can deduct that before scaling, the best performing KNN model was the one where K is 13."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919f9842",
   "metadata": {},
   "source": [
    "Due to computational complexity, we will assume that our model performs performs best when K=13 even when we add feature scaling to it (instead of testing out all combinations of feature scaling for all possible K values). Since our dataset only contains 4 features, we have decided to alter our model by scaling all of them.\n",
    "<br>In order to determine when our model performs best, we wrote a function that tests it out for different scales for each relevant feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2a08097b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now scaling Left-Weight by 10\n",
      "Now scaling Left-Weight by 25\n",
      "Now scaling Left-Weight by 50\n",
      "Now scaling Left-Weight by 100\n",
      "Now scaling Left-Weight by 150\n",
      "Now scaling Left-Weight by 200\n",
      "Now scaling Left-Distance by 10\n",
      "Now scaling Left-Distance by 25\n",
      "Now scaling Left-Distance by 50\n",
      "Now scaling Left-Distance by 100\n",
      "Now scaling Left-Distance by 150\n",
      "Now scaling Left-Distance by 200\n",
      "Now scaling Right-Weight by 10\n",
      "Now scaling Right-Weight by 25\n",
      "Now scaling Right-Weight by 50\n",
      "Now scaling Right-Weight by 100\n",
      "Now scaling Right-Weight by 150\n",
      "Now scaling Right-Weight by 200\n",
      "Now scaling Right-Distance by 10\n",
      "Now scaling Right-Distance by 25\n",
      "Now scaling Right-Distance by 50\n",
      "Now scaling Right-Distance by 100\n",
      "Now scaling Right-Distance by 150\n",
      "Now scaling Right-Distance by 200\n"
     ]
    }
   ],
   "source": [
    "X_scaling = df2_train\n",
    "scalable_features = ('Left-Weight', 'Left-Distance', 'Right-Weight', 'Right-Distance')\n",
    "KNN_cross_val_scaled2 = tools.l_fold_cross_validation_KNN_scaling_test(L=5, X=X_scaling, Y=Y2, K=13, scalable_features=scalable_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14092601",
   "metadata": {},
   "source": [
    "Let's visualize the results of our test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5868d07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tools.plot_scaling_results(KNN_cross_val_scaled2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d32ff54",
   "metadata": {},
   "source": [
    "We can deduct from this that scaling has not brought any change whatsoever to our model's performance. Thus, we have decided not to apply any scaling to our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976b5a72",
   "metadata": {},
   "source": [
    "* ### 5-fold cross validation on that same data with the Decision Tree algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "94dec881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "Done\n",
      "Performing 5-fold-cross-validation on  720  permutations of hyperparameters took  3.948081624999759  seconds\n"
     ]
    }
   ],
   "source": [
    "DT_cross_val2 = tools.l_fold_cross_validation_DT(L=5, X=X2, Y=Y2, criterion=[\"gini\", \"entropy\"],splitter=[\"best\",\"random\"],max_depth=[10,20,30,40,50],min_impurity_decrease=[0.2,0.1,0.05,0.025,0.01,0],min_samples_leaf=[1,5,10,15,20,25])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c6d269",
   "metadata": {},
   "source": [
    "We will now try to find the best hyperparameters for our Decision Tree algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "53b41800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyperparmater values are: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>splitter</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_impurity_decrease</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time_req</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.768675</td>\n",
       "      <td>0.001674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    criterion splitter max_depth  min_impurity_decrease min_samples_leaf  \\\n",
       "463   entropy     best        30                    0.0                5   \n",
       "\n",
       "     accuracy  time_req  \n",
       "463  0.768675  0.001674  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hp2 = DT_cross_val2[DT_cross_val2.accuracy == DT_cross_val2.accuracy.max()]\n",
    "# if we have a tie of best hyperparameters, choose the one with the fastest time\n",
    "if best_hp2.shape[0]>1:\n",
    "    best_hp2 = best_hp2[best_hp2.time_req == best_hp2.time_req.min()]\n",
    "print(\"best hyperparmater values are: \")\n",
    "best_hp2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d001da",
   "metadata": {},
   "source": [
    "Looking at the above table, we can easily see which are the best parameters for our Decision Tree algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119b1a65",
   "metadata": {},
   "source": [
    "* ### L-fold cross validation with KNN algorithm on that same data with L > 5:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a92792",
   "metadata": {},
   "source": [
    "Now we want to run the same experiment but with larger subsets of the training validation data. Since this will be very time-consuming, we will run the cross_validation with a smaller range of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c42116c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L =  10\n",
      "0 %\n",
      "10 %\n",
      "20 %\n",
      "30 %\n",
      "40 %\n",
      "50 %\n",
      "60 %\n",
      "70 %\n",
      "80 %\n",
      "90 %\n",
      "The best accuracy =  0.8243902439024391 , achieved for K =  2\n",
      "L =  15\n",
      "0 %\n",
      "6 %\n",
      "13 %\n",
      "20 %\n",
      "26 %\n",
      "33 %\n",
      "40 %\n",
      "46 %\n",
      "53 %\n",
      "60 %\n",
      "66 %\n",
      "73 %\n",
      "80 %\n",
      "86 %\n",
      "93 %\n",
      "The best accuracy =  0.8419753086419753 , achieved for K =  1\n",
      "L =  20\n",
      "0 %\n",
      "5 %\n",
      "10 %\n",
      "15 %\n",
      "20 %\n",
      "25 %\n",
      "30 %\n",
      "35 %\n",
      "40 %\n",
      "45 %\n",
      "50 %\n",
      "55 %\n",
      "60 %\n",
      "65 %\n",
      "70 %\n",
      "75 %\n",
      "80 %\n",
      "85 %\n",
      "90 %\n",
      "95 %\n",
      "The best accuracy =  0.8300000000000003 , achieved for K =  2\n",
      "L =  25\n",
      "0 %\n",
      "4 %\n",
      "8 %\n",
      "12 %\n",
      "16 %\n",
      "20 %\n",
      "24 %\n",
      "28 %\n",
      "32 %\n",
      "36 %\n",
      "40 %\n",
      "44 %\n",
      "48 %\n",
      "52 %\n",
      "56 %\n",
      "60 %\n",
      "64 %\n",
      "68 %\n",
      "72 %\n",
      "76 %\n",
      "80 %\n",
      "84 %\n",
      "88 %\n",
      "92 %\n",
      "96 %\n",
      "The best accuracy =  0.845 , achieved for K =  1\n",
      "L =  30\n",
      "0 %\n",
      "3 %\n",
      "6 %\n",
      "10 %\n",
      "13 %\n",
      "16 %\n",
      "20 %\n",
      "23 %\n",
      "26 %\n",
      "30 %\n",
      "33 %\n",
      "36 %\n",
      "40 %\n",
      "43 %\n",
      "46 %\n",
      "50 %\n",
      "53 %\n",
      "56 %\n",
      "60 %\n",
      "63 %\n",
      "66 %\n",
      "70 %\n",
      "73 %\n",
      "76 %\n",
      "80 %\n",
      "83 %\n",
      "86 %\n",
      "90 %\n",
      "93 %\n",
      "96 %\n",
      "The best accuracy =  0.8410256410256413 , achieved for K =  2\n",
      "L =  35\n",
      "0 %\n",
      "2 %\n",
      "5 %\n",
      "8 %\n",
      "11 %\n",
      "14 %\n",
      "17 %\n",
      "20 %\n",
      "22 %\n",
      "25 %\n",
      "28 %\n",
      "31 %\n",
      "34 %\n",
      "37 %\n",
      "40 %\n",
      "42 %\n",
      "45 %\n",
      "48 %\n",
      "51 %\n",
      "54 %\n",
      "57 %\n",
      "60 %\n",
      "62 %\n",
      "65 %\n",
      "68 %\n",
      "71 %\n",
      "74 %\n",
      "77 %\n",
      "80 %\n",
      "82 %\n",
      "85 %\n",
      "88 %\n",
      "91 %\n",
      "94 %\n",
      "97 %\n",
      "The best accuracy =  0.8493506493506492 , achieved for K =  2\n",
      "L =  40\n",
      "0 %\n",
      "2 %\n",
      "5 %\n",
      "7 %\n",
      "10 %\n",
      "12 %\n",
      "15 %\n",
      "17 %\n",
      "20 %\n",
      "22 %\n",
      "25 %\n",
      "27 %\n",
      "30 %\n",
      "32 %\n",
      "35 %\n",
      "37 %\n",
      "40 %\n",
      "42 %\n",
      "45 %\n",
      "47 %\n",
      "50 %\n",
      "52 %\n",
      "55 %\n",
      "57 %\n",
      "60 %\n",
      "62 %\n",
      "65 %\n",
      "67 %\n",
      "70 %\n",
      "72 %\n",
      "75 %\n",
      "77 %\n",
      "80 %\n",
      "82 %\n",
      "85 %\n",
      "87 %\n",
      "90 %\n",
      "92 %\n",
      "95 %\n",
      "97 %\n",
      "The best accuracy =  0.85 , achieved for K =  2\n"
     ]
    }
   ],
   "source": [
    "for l in [10,15,20,25,30,35,40]:\n",
    "    print(\"L = \", l)\n",
    "    KNN_cross_val2 = tools.l_fold_cross_validation_KNN(L=l, X=X2, Y=Y2, K=[5,10,11,15])\n",
    "    argmax = KNN_cross_val2.argmax()\n",
    "    print(\"The best accuracy = \", KNN_cross_val2.max(), \", achieved for K = \", argmax+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c84131",
   "metadata": {},
   "source": [
    "We want to understand how the size of a dataset impacts both the training and validation error.\n",
    "<br>We can see that as L increases, or more specifically when L > 5, K seems to be stabilising around 2 as it's best value, which is low when compared to our previous best value when L = 5, 13.\n",
    "<br>However, the accuracy seems to be relatively unchanged when compared to the previous accuracy we achieved when using 5-fol cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2308d237",
   "metadata": {},
   "source": [
    "* ### L-fold cross validation with the Decision Tree algorithm on that same data with L > 5:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01135e11",
   "metadata": {},
   "source": [
    "As for the KNN algorithm, we will run the cross_validation with a smaller range of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "62d623f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L =  10\n",
      "0 %\n",
      "10 %\n",
      "20 %\n",
      "30 %\n",
      "40 %\n",
      "50 %\n",
      "60 %\n",
      "70 %\n",
      "80 %\n",
      "90 %\n",
      "Done\n",
      "Performing 10-fold-cross-validation on  144  permutations of hyperparameters took  1.345486540998536  seconds\n",
      "The best hyperparmater values are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>splitter</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_impurity_decrease</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time_req</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>entropy</td>\n",
       "      <td>random</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.003429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    criterion splitter max_depth  min_impurity_decrease min_samples_leaf  \\\n",
       "138   entropy   random        15                    0.0                1   \n",
       "\n",
       "     accuracy  time_req  \n",
       "138  0.780488  0.003429  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L =  15\n",
      "0 %\n",
      "6 %\n",
      "13 %\n",
      "20 %\n",
      "26 %\n",
      "33 %\n",
      "40 %\n",
      "46 %\n",
      "53 %\n",
      "60 %\n",
      "66 %\n",
      "73 %\n",
      "80 %\n",
      "86 %\n",
      "93 %\n",
      "Done\n",
      "Performing 15-fold-cross-validation on  144  permutations of hyperparameters took  1.9023771250031132  seconds\n",
      "The best hyperparmater values are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>splitter</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_impurity_decrease</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time_req</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>entropy</td>\n",
       "      <td>random</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.004271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    criterion splitter max_depth  min_impurity_decrease min_samples_leaf  \\\n",
       "139   entropy   random        15                    0.0                5   \n",
       "\n",
       "     accuracy  time_req  \n",
       "139  0.790123  0.004271  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L =  20\n",
      "0 %\n",
      "5 %\n",
      "10 %\n",
      "15 %\n",
      "20 %\n",
      "25 %\n",
      "30 %\n",
      "35 %\n",
      "40 %\n",
      "45 %\n",
      "50 %\n",
      "55 %\n",
      "60 %\n",
      "65 %\n",
      "70 %\n",
      "75 %\n",
      "80 %\n",
      "85 %\n",
      "90 %\n",
      "95 %\n",
      "Done\n",
      "Performing 20-fold-cross-validation on  144  permutations of hyperparameters took  2.526824749998923  seconds\n",
      "The best hyperparmater values are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>splitter</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_impurity_decrease</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time_req</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7925</td>\n",
       "      <td>0.006629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    criterion splitter max_depth  min_impurity_decrease min_samples_leaf  \\\n",
       "103   entropy     best        15                    0.0                5   \n",
       "\n",
       "     accuracy  time_req  \n",
       "103    0.7925  0.006629  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L =  25\n",
      "0 %\n",
      "4 %\n",
      "8 %\n",
      "12 %\n",
      "16 %\n",
      "20 %\n",
      "24 %\n",
      "28 %\n",
      "32 %\n",
      "36 %\n",
      "40 %\n",
      "44 %\n",
      "48 %\n",
      "52 %\n",
      "56 %\n",
      "60 %\n",
      "64 %\n",
      "68 %\n",
      "72 %\n",
      "76 %\n",
      "80 %\n",
      "84 %\n",
      "88 %\n",
      "92 %\n",
      "96 %\n",
      "Done\n",
      "Performing 25-fold-cross-validation on  144  permutations of hyperparameters took  3.1227833750017453  seconds\n",
      "The best hyperparmater values are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>splitter</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_impurity_decrease</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time_req</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.0102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    criterion splitter max_depth  min_impurity_decrease min_samples_leaf  \\\n",
       "102   entropy     best        15                    0.0                1   \n",
       "\n",
       "     accuracy  time_req  \n",
       "102     0.795    0.0102  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L =  30\n",
      "0 %\n",
      "3 %\n",
      "6 %\n",
      "10 %\n",
      "13 %\n",
      "16 %\n",
      "20 %\n",
      "23 %\n",
      "26 %\n",
      "30 %\n",
      "33 %\n",
      "36 %\n",
      "40 %\n",
      "43 %\n",
      "46 %\n",
      "50 %\n",
      "53 %\n",
      "56 %\n",
      "60 %\n",
      "63 %\n",
      "66 %\n",
      "70 %\n",
      "73 %\n",
      "76 %\n",
      "80 %\n",
      "83 %\n",
      "86 %\n",
      "90 %\n",
      "93 %\n",
      "96 %\n",
      "Done\n",
      "Performing 30-fold-cross-validation on  144  permutations of hyperparameters took  3.6685095409993664  seconds\n",
      "The best hyperparmater values are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>splitter</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_impurity_decrease</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time_req</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.787179</td>\n",
       "      <td>0.00912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   criterion splitter max_depth  min_impurity_decrease min_samples_leaf  \\\n",
       "14      gini     best        10                    0.0               10   \n",
       "\n",
       "    accuracy  time_req  \n",
       "14  0.787179   0.00912  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L =  35\n",
      "0 %\n",
      "2 %\n",
      "5 %\n",
      "8 %\n",
      "11 %\n",
      "14 %\n",
      "17 %\n",
      "20 %\n",
      "22 %\n",
      "25 %\n",
      "28 %\n",
      "31 %\n",
      "34 %\n",
      "37 %\n",
      "40 %\n",
      "42 %\n",
      "45 %\n",
      "48 %\n",
      "51 %\n",
      "54 %\n",
      "57 %\n",
      "60 %\n",
      "62 %\n",
      "65 %\n",
      "68 %\n",
      "71 %\n",
      "74 %\n",
      "77 %\n",
      "80 %\n",
      "82 %\n",
      "85 %\n",
      "88 %\n",
      "91 %\n",
      "94 %\n",
      "97 %\n",
      "Done\n",
      "Performing 35-fold-cross-validation on  144  permutations of hyperparameters took  4.246664791000512  seconds\n",
      "The best hyperparmater values are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>splitter</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_impurity_decrease</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time_req</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.784416</td>\n",
       "      <td>0.013869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    criterion splitter max_depth  min_impurity_decrease min_samples_leaf  \\\n",
       "102   entropy     best        15                    0.0                1   \n",
       "\n",
       "     accuracy  time_req  \n",
       "102  0.784416  0.013869  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L =  40\n",
      "0 %\n",
      "2 %\n",
      "5 %\n",
      "7 %\n",
      "10 %\n",
      "12 %\n",
      "15 %\n",
      "17 %\n",
      "20 %\n",
      "22 %\n",
      "25 %\n",
      "27 %\n",
      "30 %\n",
      "32 %\n",
      "35 %\n",
      "37 %\n",
      "40 %\n",
      "42 %\n",
      "45 %\n",
      "47 %\n",
      "50 %\n",
      "52 %\n",
      "55 %\n",
      "57 %\n",
      "60 %\n",
      "62 %\n",
      "65 %\n",
      "67 %\n",
      "70 %\n",
      "72 %\n",
      "75 %\n",
      "77 %\n",
      "80 %\n",
      "82 %\n",
      "85 %\n",
      "87 %\n",
      "90 %\n",
      "92 %\n",
      "95 %\n",
      "97 %\n",
      "Done\n",
      "Performing 40-fold-cross-validation on  144  permutations of hyperparameters took  4.804851332999533  seconds\n",
      "The best hyperparmater values are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>splitter</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_impurity_decrease</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time_req</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.0123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   criterion splitter max_depth  min_impurity_decrease min_samples_leaf  \\\n",
       "86   entropy     best        10                    0.0               10   \n",
       "\n",
       "    accuracy  time_req  \n",
       "86    0.8125    0.0123  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for l in [10,15,20,25,30,35,40]:\n",
    "    print(\"L = \", l)\n",
    "    DT_cross_val2 = tools.l_fold_cross_validation_DT(L=l, X=X2, Y=Y2,criterion=[\"gini\", \"entropy\"],splitter=[\"best\",\"random\"],max_depth=[10,15],min_impurity_decrease=[0.1,0.025,0],min_samples_leaf=[1,5,10,15,20,25])\n",
    "    best_hp2 = DT_cross_val2[DT_cross_val2.accuracy == DT_cross_val2.accuracy.max()]\n",
    "    # if we have a tie of best hyperparameters, choose the one with the fastest time\n",
    "    if best_hp2.shape[0]>1:\n",
    "        best_hp2 = best_hp2[best_hp2.time_req == best_hp2.time_req.min()]\n",
    "    print(\"The best hyperparmater values are:\")\n",
    "    display(best_hp2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc74a69",
   "metadata": {},
   "source": [
    "We want to understand how the size of a dataset impacts both the training and validation error\n",
    "<br>Looking at the above tables, we notice that as L increases, some hyperparameters that lead to optimal results are different than when L = 5 (Maximum depth has decreased significantly from 30 to about 10-15,  ...). As for the accuracy, it increases a bit (~2.1% on average when L > 5) although this doesn't necessarily imply a correlation between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451e3e76",
   "metadata": {},
   "source": [
    "### Applying our model on unseen data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5907e7ca",
   "metadata": {},
   "source": [
    "Now, let's check our performance on the test data. Unlike our first dataset where the test data was located in a seperate file, in this case we have already split the data into train set and test set. Thus, we can jump right into it:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0725e175",
   "metadata": {},
   "source": [
    "* ### KNN on unseen data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232b51da",
   "metadata": {},
   "source": [
    "We now run our KNN model on unseen data using the optimal K we have found earlier (13):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "96c6ee25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k =  13 the accuracy on the test data is:  0.3605769230769231\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# see training data results on KNN using K=13\n",
    "KNN_classifier2 = KNN(n_neighbors=13)\n",
    "KNN_classifier2.fit(X2, Y2) # fit the model using training data\n",
    "Y_prediction2 = KNN_classifier2.predict(X2_test) # predict test data\n",
    "accuracy2 = Y_prediction2 == Y2_test\n",
    "accuracy2 = np.sum(accuracy2)  # number of correct predictions\n",
    "score2 = accuracy2 / X2_test.shape[0]  # ratio of correct prediction\n",
    "print(\"For k = \", k, \"the accuracy on the test data is: \", score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d59cb0",
   "metadata": {},
   "source": [
    "Based on those results, we can estimate an accuracy of 36.06% on unseen data with our KNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dd1ba9",
   "metadata": {},
   "source": [
    "* ### Decision Tree algorithm on unseen data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521af062",
   "metadata": {},
   "source": [
    "Using the best hyperparameters for our model when L = 5, we run our Decision Tree algorithm on unseen data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "41ec22e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the best hyperparameters, the accuracy is:  0.46634615384615385\n"
     ]
    }
   ],
   "source": [
    "# DT\n",
    "# predict on test data using best hyperparameters\n",
    "DT_classifier2 = DT(criterion=\"entropy\", splitter=\"best\", max_depth=30,\n",
    "                min_impurity_decrease=0, min_samples_leaf=5)\n",
    "DT_classifier2.fit(X2, Y2)\n",
    "Y_prediction2 = DT_classifier2.predict(X2_test)\n",
    "accuracy2 = Y_prediction2 == Y2_test\n",
    "accuracy2 = np.sum(accuracy2)  # number of correct predictions\n",
    "score2 = accuracy2/X2_test.shape[0]\n",
    "print(\"For the best hyperparameters, the accuracy is: \", score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6d3cc4",
   "metadata": {},
   "source": [
    "<br>Assuming our model performs best under these parameters, we can estimate an accuracy of 46.63% on unseen data with our Decision Tree model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
